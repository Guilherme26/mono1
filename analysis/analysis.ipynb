{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Set a seed ✓\n",
    "- Read data ✓\n",
    "- Check nulls ✓\n",
    "- How many users? ✓\n",
    "- How many categories? ✓\n",
    "    - How much records does each one have? ✓\n",
    "- How many posts? ✓\n",
    "- How many interactions? ✓\n",
    "- What is the average interactions per post? ✓\n",
    "- Remove \"insignificant\" connections. ✓\n",
    "- How representative was the reduction? ✓\n",
    "- Create a reasonable visualization from the graph (e.g. Gephi)\n",
    "- Create a mapping from all names to indices (e.g. LabelEncoder). How to get all names? ✓\n",
    "- Create a mapping from all labels to an indices. ✓\n",
    "- Create a mapping from all nodes to a label index. ✓\n",
    "- Create a toy model (e.g. the GCN example provided in the documentation). ✓\n",
    "- Check if the data object was created correctly. \n",
    "- Define the embedding dimension.\n",
    "- Create and save a [Node2Vec](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.models.Node2Vec) model. ✓\n",
    "- Create and save a [GCN](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) model. ✓\n",
    "- Create ans save a [GAT](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GATConv) model. ✓\n",
    "- Create ans save a [SAGE](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv) model.\n",
    "- Create ans save a [GIN](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GINConv) model.\n",
    "- Use a t-SNE and plot the classes with different colors.\n",
    "- How consistent are the embeddings? \n",
    "- Do they group well together?\n",
    "- From which models does the greatest embeddings come from?\n",
    "- Which metric will be optimized by the learning models?\n",
    "- Which model should be used to classify the nodes?\n",
    "    - If a neural model:\n",
    "        - Which learning rate? Is it adaptive? \n",
    "        - How many epochs? \n",
    "        - Which architecture?\n",
    "        - Present a training erro vs test error analysis chart.\n",
    "- Which categories reach the greatest performance? \n",
    "    - Why?\n",
    "    - Is there any pausible reason or maybe characteristic from a method/family of methods that helps to perform better in our case? If so, what is?\n",
    "- \n",
    "   \n",
    "Resources:\n",
    "- https://graphreason.github.io/papers/39.pdf (Must Read)\n",
    "- https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\n",
    "- https://pytorch-geometric.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many comments did a user make? - OK \n",
    "# In how many categories does the commenter posted on? - OK\n",
    "# How many user does the commenter mentions, on average? - OK\n",
    "# How many tags is used by the commenter, on average? - OK\n",
    "# What hour of day do he/she made more comments?\n",
    "# What is day of week in which the user made more comments?\n",
    "# What is the average message length? - OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn.models import Node2Vec\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv\n",
    "from torch.optim import Adam\n",
    "from torch.nn import NLLLoss\n",
    "from collections import defaultdict\n",
    "from dateutil import parser\n",
    "\n",
    "import ast\n",
    "import preprocessing\n",
    "import utils\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "profiles = pd.read_csv(\"../data/profiles.csv\", usecols=[\"profile_username\", \"profile_followed_by\", \"profile_follow\", \n",
    "                                                        \"medias_nb\", \"comments_nb\", \"comments_commenters_nb\", \n",
    "                                                        \"comments_self_nb\", \"category_1\"])\n",
    "comments = pd.read_csv(\"../data/comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.filter_by_relevance(comments, profiles, minimum_freq=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = comments[[\"media_author\", \"commenter\"]]\\\n",
    "                .groupby(\"commenter\", as_index=False)\\\n",
    "                .agg(\"count\")\\\n",
    "                .sort_values(\"commenter\")\n",
    "final_df.columns = [\"commenter\", \"comments_nb\"]\n",
    "final_df = final_df[final_df.comments_nb >= 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of commenters: {}\".format(len(final_df)))\n",
    "comments = comments[comments.commenter.isin(final_df.commenter.values)]\n",
    "print(\"The current number of interactions: {}\".format(len(comments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = comments[[\"category_1\", \"commenter\"]]\\\n",
    "            .groupby(\"commenter\", as_index=False)\\\n",
    "            .agg({\"category_1\": lambda col: col.nunique()})\\\n",
    "            .sort_values(\"commenter\")\n",
    "\n",
    "to_categories_nb = {commenter: categories_nb for commenter, categories_nb in tmp.values}\n",
    "final_df[\"categories_nb\"] = final_df.commenter.apply(lambda commenter: to_categories_nb[commenter])\n",
    "\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = comments[[\"commenter\", \"comment_tags\"]]\n",
    "tmp[\"comment_tags\"] = tmp.comment_tags.apply(lambda x: len(ast.literal_eval(x)))\n",
    "tmp = tmp.groupby(\"commenter\", as_index=False)\\\n",
    "            .agg(\"mean\")\\\n",
    "            .sort_values(\"commenter\")\n",
    "\n",
    "to_avg_tags_nb = {commenter: avg_tags_nb for commenter, avg_tags_nb in tmp.values}\n",
    "final_df[\"avg_tags_nb\"] = final_df.commenter.apply(lambda commenter: to_avg_tags_nb[commenter])\n",
    "\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = comments[[\"commenter\", \"comment_mentioned_usernames\"]]\n",
    "tmp[\"comment_mentioned_usernames\"] = tmp.comment_mentioned_usernames.apply(lambda x: len(ast.literal_eval(x)))\n",
    "tmp = tmp.groupby(\"commenter\", as_index=False)\\\n",
    "            .agg(\"mean\")\\\n",
    "            .sort_values(\"commenter\")\n",
    "\n",
    "to_avg_cited_users = {commenter: avg_cited_users for commenter, avg_cited_users in tmp.values}\n",
    "final_df[\"avg_cited_users\"] = final_df.commenter.apply(lambda commenter: to_avg_cited_users[commenter])\n",
    "\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = comments[[\"commenter\", \"comment_text\"]]\n",
    "tmp[\"comment_text\"] = tmp.comment_text.apply(lambda x: len(x))\n",
    "tmp = tmp.groupby(\"commenter\", as_index=False)\\\n",
    "            .agg(\"mean\")\\\n",
    "            .sort_values(\"commenter\")\n",
    "\n",
    "to_avg_msg_len = {commenter: avg_msg_len for commenter, avg_msg_len in tmp.values}\n",
    "final_df[\"avg_msg_len\"] = final_df.commenter.apply(lambda commenter: to_avg_msg_len[commenter])\n",
    "\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict(to_weekday, commenter, day, freq):\n",
    "    if to_weekday[commenter][1] < freq:\n",
    "        to_weekday[commenter] = (day, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = comments[[\"commenter\", \"comment_created_time_str\"]]\n",
    "tmp[\"day\"] = tmp.comment_created_time_str.apply(lambda item: parser.parse(item).weekday())\n",
    "tmp = tmp.groupby([\"commenter\", \"day\"], as_index=False).agg(\"count\")\n",
    "\n",
    "to_weekday = {}\n",
    "for commenter, day, freq in tmp.values:\n",
    "    if not commenter in to_weekday:\n",
    "        to_weekday[commenter] = (0, 0)\n",
    "    \n",
    "    update_dict(to_weekday, commenter, day, freq)\n",
    "    \n",
    "final_df[\"weekday\"] = final_df.commenter.apply(lambda commenter: to_weekday[commenter][0])\n",
    "\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = comments[[\"commenter\", \"comment_created_time_str\"]]\n",
    "tmp[\"hour\"] = tmp.comment_created_time_str.apply(lambda item: parser.parse(item).hour)\n",
    "tmp = tmp.groupby([\"commenter\", \"hour\"], as_index=False).agg(\"count\")\n",
    "\n",
    "to_hour = {}\n",
    "for commenter, hour, freq in tmp.values:\n",
    "    if not commenter in to_hour:\n",
    "        to_hour[commenter] = (0, 0)\n",
    "    \n",
    "    update_dict(to_hour, commenter, hour, freq)\n",
    "    \n",
    "final_df[\"hour\"] = final_df.commenter.apply(lambda commenter: to_hour[commenter][0])\n",
    "\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"not_tracked_user\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = profiles.category_1.value_counts()\n",
    "print(results)\n",
    "\n",
    "figure = go.Figure(\n",
    "    data=[go.Pie(labels=results.index.values, values=results.values)],\n",
    "    layout_title_text=\"Percentage of Each Category\"\n",
    ")\n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = profiles.profile_username.unique().tolist()\n",
    "followers = comments.commenter.unique().tolist()\n",
    "all_users = set(known_users + followers)\n",
    "prev_number_of_users = len(all_users)\n",
    "print(\"There are originally {} users\".format(prev_number_of_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts = len(comments.media_short_code.unique())\n",
    "all_interactions = len(comments)\n",
    "print(\"There are {} distinct posts and {} interactions. An average of {} interactions per post\"\\\n",
    "          .format(all_posts, all_interactions, np.round(all_interactions/all_posts, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = preprocessing.categorical_to_numerical(profiles, col=\"category_1\")\n",
    "comments = comments.drop_duplicates()\n",
    "comments = preprocessing.filter_by_relevance(comments, profiles, minimum_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = profiles.profile_username.unique().tolist()\n",
    "followers = comments.commenter.unique().tolist()\n",
    "all_users = set(known_users + followers)\n",
    "cur_number_of_users = len(all_users)\n",
    "print(\"The new graph drawn from relevance threshold {} has {} users and {} interactions\"\\\n",
    "          .format(35, cur_number_of_users, len(comments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of users was reduced by ~ {}%\"\\\n",
    "          .format(np.round((1-cur_number_of_users/prev_number_of_users)*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = profiles.profile_username.values\n",
    "data = profiles[[\"profile_followed_by\", \"profile_follow\", \"medias_nb\", \n",
    "                \"comments_nb\", \"comments_commenters_nb\", \"comments_self_nb\"]].values\n",
    "name_to_record = {name: record for name, record in zip(names, data)}\n",
    "\n",
    "input_dim, output_dim = data.shape[1], len(profiles.category_1.unique()) + 1\n",
    "user_to_label = {user: category for user, category in profiles[[\"profile_username\", \"category_1\"]].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_histories(models_histories, new_histories):\n",
    "    for model, history in new_histories.items():\n",
    "        if not models_histories[model]:\n",
    "            models_histories[model] = np.array(new_histories[model])\n",
    "        else:\n",
    "            models_histories[model] += np.array(new_histories[model])\n",
    "    \n",
    "    return models_histories\n",
    "    \n",
    "\n",
    "def calculate_statistics(models_metrics):\n",
    "    return {model: {metric: (np.mean(values), np.std(values)) for metric, values in metrics.items()} \n",
    "                for model, metrics in models_metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "skf = StratifiedKFold(n_splits=K)\n",
    "\n",
    "n_hidden_units = 64\n",
    "print(\"Fez of preprocessamento\")\n",
    "models_metrics = defaultdict(dict)\n",
    "models_histories = defaultdict(list)\n",
    "for train_idx, test_idx in skf.split(profiles.profile_username.values, profiles.category_1.values):\n",
    "    train_authors, test_authors = utils.get_authors(profiles, all_users, train_idx, test_idx)\n",
    "\n",
    "    print(\"Pegou autores\")\n",
    "\n",
    "    username_to_index = utils.get_users_indices(train_authors)\n",
    "    print(\"Pegou indices\")\n",
    "    train_interactions = utils.get_interactions(comments[(comments.media_author.isin(train_authors)) \n",
    "                                                    & (comments.commenter.isin(train_authors))], username_to_index)\n",
    "    print(\"Pegou interações\")\n",
    "    x_train, y_train = utils.get_x(train_authors, name_to_record, input_dim=input_dim), utils.get_y(user_to_label, train_authors)\n",
    "    print(\"Pegou x e y\")\n",
    "    assert len(x_train)==len(y_train), \"Train Input and Output tensor do not have the same dimensions\"\n",
    "\n",
    "\n",
    "    edge_index = utils.get_edge_index(train_interactions)\n",
    "    print(\"Pegou os indices de arestas\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data = Data(x=x_train, y=y_train, edge_index=edge_index).to(device)\n",
    "    print(\"Criou Data\")\n",
    "\n",
    "    models = utils.get_models(data.num_nodes, input_dim, output_dim, n_hidden_units, device=device, lr=0.005)\n",
    "    print(\"Criou modelos\")\n",
    "\n",
    "    histories = utils.train(data, models, epochs=1)\n",
    "    models_histories = update_histories(models_histories, histories)\n",
    "\n",
    "    username_to_index = utils.get_users_indices(test_authors)\n",
    "    test_interactions = utils.get_interactions(comments[(comments.media_author.isin(test_authors)) \n",
    "                                                    & (comments.commenter.isin(test_authors))], username_to_index)\n",
    "    x_test, y_test = utils.get_x(test_authors, name_to_record, input_dim=input_dim), utils.get_y(user_to_label, test_authors)\n",
    "    assert len(x_test)==len(y_test), \"Test Input and Output tensor do not have the same dimensions\"\n",
    "\n",
    "    edge_index = utils.get_edge_index(test_interactions)\n",
    "    data = Data(x=x_test, y=y_test, edge_index=edge_index).to(device)\n",
    "    current_metrics = utils.test(data, models)\n",
    "    utils.update_metrics_dict(models_metrics, current_metrics)\n",
    "    \n",
    "models_histories = {model: list(history/K) for model, history in models_histories.items()} # Get mean traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metrics = calculate_statistics(models_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "models_histories = json.load(open(\"../pipeline/results/one_layer_models/models_histories_1_256.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, sharey=True)\n",
    "models = [\"GCN\", \"GAT\", \"GraphSAGE\"]\n",
    "for i, (model, history) in enumerate(models_histories.items()):\n",
    "    ax[i].plot(range(len(history)), history)\n",
    "    ax[i].set_title(models[i])\n",
    "\n",
    "plt.suptitle(\"History of Training Error (200 Epochs)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "models_histories = json.load(open(\"../pipeline/results/one_layer_models/models_metrics_1_64.json\"))\n",
    "models_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
