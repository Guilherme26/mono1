{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Set a seed ✓\n",
    "- Read data ✓\n",
    "- Check nulls ✓\n",
    "- How many users? ✓\n",
    "- How many categories? ✓\n",
    "    - How much records does each one have? ✓\n",
    "- How many posts? ✓\n",
    "- How many interactions? ✓\n",
    "- What is the average interactions per post? ✓\n",
    "- Remove \"insignificant\" connections. ✓\n",
    "- How representative was the reduction? ✓\n",
    "- Create a reasonable visualization from the graph (e.g. Gephi)\n",
    "- Create a mapping from all names to indices (e.g. LabelEncoder). How to get all names? ✓\n",
    "- Create a mapping from all labels to an indices. ✓\n",
    "- Create a mapping from all nodes to a label index. ✓\n",
    "- Create a toy model (e.g. the GCN example provided in the documentation). ✓\n",
    "- Check if the data object was created correctly. \n",
    "- Define the embedding dimension.\n",
    "- Create and save a [Node2Vec](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.models.Node2Vec) model. ✓\n",
    "- Create and save a [GCN](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) model. ✓\n",
    "- Create ans save a [GAT](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GATConv) model. ✓\n",
    "- Create ans save a [SAGE](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv) model.\n",
    "- Create ans save a [GIN](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GINConv) model.\n",
    "- Use a t-SNE and plot the classes with different colors.\n",
    "- How consistent are the embeddings? \n",
    "- Do they group well together?\n",
    "- From which models does the greatest embeddings come from?\n",
    "- Which metric will be optimized by the learning models?\n",
    "- Which model should be used to classify the nodes?\n",
    "    - If a neural model:\n",
    "        - Which learning rate? Is it adaptive? \n",
    "        - How many epochs? \n",
    "        - Which architecture?\n",
    "        - Present a training erro vs test error analysis chart.\n",
    "- Which categories reach the greatest performance? \n",
    "    - Why?\n",
    "    - Is there any pausible reason or maybe characteristic from a method/family of methods that helps to perform better in our case? If so, what is?\n",
    "- \n",
    "   \n",
    "Resources:\n",
    "- https://graphreason.github.io/papers/39.pdf (Must Read)\n",
    "- https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\n",
    "- https://pytorch-geometric.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn.models import Node2Vec\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv\n",
    "from torch.optim import Adam\n",
    "from torch.nn import NLLLoss\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node2VecModel(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Node2VecModel, self).__init__()\n",
    "        self.model = Node2Vec(*args, **kwargs)\n",
    "        \n",
    "        self.optimizer = Adam(self.model.parameters(), lr=0.01)\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "        \n",
    "    def fit(self, data, epochs=10):\n",
    "        data_loader = DataLoader(torch.arange(data.num_nodes), batch_size=64, shuffle=True)\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for subset in data_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model.loss(data.edge_index, subset)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            print(\"Node2Vec running loss is: {}\".format(running_loss / len(subset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_hidden_units, n_classes, **kwargs):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(n_features, n_hidden_units, cached=True)\n",
    "        self.conv2 = GCNConv(n_hidden_units, n_classes, cached=True)\n",
    "        \n",
    "        self.loss = NLLLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs=10):\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.forward(data.x, data.edge_index)\n",
    "            loss = self.loss(outputs, data.y)\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            print(\"GCN running loss is: {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_hidden_units, n_classes, lr=0.01):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(n_features, n_hidden_units, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(n_hidden_units**2, n_classes, heads=1, concat=True, dropout=0.6)\n",
    "        \n",
    "        self.loss = NLLLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs=10):\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            outputs = self.forward(data.x, data.edge_index)\n",
    "            loss = self.loss(outputs[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            print(\"GAT running loss is: {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_hidden_units, n_classes, lr=0.01):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(n_features, n_hidden_units)\n",
    "        self.conv2 = SAGEConv(n_hidden_units, n_classes)\n",
    "        \n",
    "        self.loss = NLLLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs=10):\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            outputs = self.forward(data.x, data.edge_index)\n",
    "            loss = self.loss(outputs, data.y)\n",
    "            loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            print(\"GraphSAGE running loss is: {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv(\"../data/profiles.csv\", usecols=[\"profile_username\", \"profile_followed_by\", \"profile_follow\", \n",
    "                                                        \"medias_nb\", \"comments_nb\", \"comments_commenters_nb\", \n",
    "                                                        \"comments_self_nb\", \"category_1\"])\n",
    "profiles.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"../data/comments.csv\", usecols=[\"media_short_code\", \"media_author\", \"commenter\"])\n",
    "comments = comments.drop_duplicates()\n",
    "comments.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = profiles.category_1.value_counts()\n",
    "\n",
    "figure = go.Figure(\n",
    "    data=[go.Pie(labels=results.index.values, values=results.values)],\n",
    "    layout_title_text=\"Percentage of Each Category\"\n",
    ")\n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_index = {category: index for index, category in enumerate(results.index)}\n",
    "profiles.category_1 = profiles.category_1.map(lambda key: category_to_index[key])\n",
    "profiles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = profiles.profile_username.unique().tolist()\n",
    "followers = comments.commenter.unique().tolist()\n",
    "prev_number_of_users = len(set(known_users + followers))\n",
    "\n",
    "print(\"There are originally {} users\".format(prev_number_of_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts = len(comments.media_short_code.unique())\n",
    "all_interactions = len(comments)\n",
    "print(\"There are {} distinct posts and {} interactions. An average of {} interactions per post\"\\\n",
    "          .format(all_posts, all_interactions, np.round(all_interactions/all_posts, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEVANCE_THRESHOLD = 50\n",
    "subgraph = []\n",
    "\n",
    "action_authors = pd.concat([comments.commenter.value_counts(), comments.media_author.value_counts()])\n",
    "action_authors = action_authors.groupby(action_authors.index).agg(\"sum\")\n",
    "for commenter, frequency in action_authors.items():\n",
    "    if (frequency > RELEVANCE_THRESHOLD) or (commenter in known_users):\n",
    "        subgraph.append(commenter)\n",
    "        \n",
    "comments = comments[comments.commenter.isin(subgraph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = profiles.profile_username.unique().tolist()\n",
    "followers = comments.commenter.unique().tolist()\n",
    "all_users = set(known_users + followers)\n",
    "cur_number_of_users = len(all_users)\n",
    "\n",
    "print(\"The new graph drawn from relevance threshold {} has {} users and {} interactions\"\\\n",
    "          .format(RELEVANCE_THRESHOLD, cur_number_of_users, len(comments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of users was reduced by ~ {}%\"\\\n",
    "          .format(np.round(1-cur_number_of_users/prev_number_of_users, 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username_to_index = {name: index for index, name in enumerate(all_users)}\n",
    "all_users_indices = [username_to_index[user] for user in username_to_index]\n",
    "\n",
    "names = profiles.profile_username.values\n",
    "data = profiles[[\"profile_followed_by\", \"profile_follow\", \"medias_nb\", \n",
    "                \"comments_nb\", \"comments_commenters_nb\", \"comments_self_nb\"]].values\n",
    "index_to_record = {username_to_index[name]: record for name, record in zip(names, data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim, output_dim = data.shape[1], len(profiles.category_1.unique()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_label = {user: category for user, category in profiles[[\"profile_username\", \"category_1\"]].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [(username_to_index[author], username_to_index[commenter]) \n",
    "                    for author, commenter in comments[['media_author', 'commenter']].drop_duplicates().values]\n",
    "\n",
    "print(\"The final graph has {} interactions\".format(len(interactions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interactions(df, username_to_index):\n",
    "    return [(username_to_index[author], username_to_index[commenter]) \n",
    "                for author, commenter in df[['media_author', 'commenter']].drop_duplicates().values]\n",
    "\n",
    "\n",
    "def get_authors(df, all_users, train_idx, test_idx):\n",
    "    train_users = list(all_users - set(profiles.iloc[test_idx].profile_username.values))\n",
    "    return train_users, profiles.iloc[test_idx].profile_username.values\n",
    "\n",
    "\n",
    "def get_edge_index(interactions):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from(interactions)\n",
    "    \n",
    "    return torch.tensor(nx.to_pandas_edgelist(graph).values.T, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_x(users_indices, index_to_record, input_dim=6):\n",
    "    x = [index_to_record.get(index, np.ones(input_dim)) for index in users_indices]\n",
    "    return torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "\n",
    "def get_y(user_to_label, users):\n",
    "    y = [user_to_label.get(user, 4) for user in users]\n",
    "    return torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_models(n_nodes, input_dim, output_dim, n_hidden_units, device='cpu'):\n",
    "    models = [Node2VecModel(data.num_nodes, embedding_dim=n_hidden_units, walk_length=20, context_size=10, walks_per_node=10), \n",
    "              GCNModel(input_dim, n_hidden_units, output_dim),\n",
    "              GATModel(input_dim, n_hidden_units, output_dim), \n",
    "              GraphSAGE(input_dim, n_hidden_units, output_dim)]\n",
    "    \n",
    "    return [model.to(device) for model in models]\n",
    "\n",
    "\n",
    "def get_users_indices(authors):\n",
    "    username_to_index = {name: index for index, name in enumerate(authors)}\n",
    "    user_indices = [username_to_index[user] for user in username_to_index.keys()]\n",
    "    return username_to_index, user_indices\n",
    "\n",
    "\n",
    "def train(data, models, epochs=10):\n",
    "    for model in models:\n",
    "        model.fit(data, epochs=epochs)\n",
    "        \n",
    "\n",
    "def test(data, models):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for n_hidden_units in [64, 128, 256]:\n",
    "    for train_idx, test_idx in skf.split(profiles.profile_username.values, profiles.category_1.values):\n",
    "        train_authors, test_authors = get_authors(profiles, all_users, train_idx, test_idx)\n",
    "\n",
    "        username_to_index, users_indices = get_users_indices(train_authors)\n",
    "        train_interactions = get_interactions(comments[(comments.media_author.isin(train_authors)) \n",
    "                                                           & (comments.commenter.isin(train_authors))], username_to_index)\n",
    "        x_train, y_train = get_x(users_indices, index_to_record, input_dim=input_dim), get_y(user_to_label, train_authors)\n",
    "        assert len(x_train)==len(y_train), \"Input and Output tensor do not have the same dimensions\"\n",
    "\n",
    "        edge_index = get_edge_index(train_interactions)\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        data = Data(x=x_train, y=y_train, edge_index=edge_index).to(device)\n",
    "\n",
    "        models = get_models(data.num_nodes, input_dim, output_dim, n_hidden_units, device=device)\n",
    "\n",
    "        train(data, models)\n",
    "\n",
    "        username_to_index, users_indices = get_users_indices(test_authors)\n",
    "        test_interactions = get_interactions(comments[(comments.media_author.isin(test_authors)) \n",
    "                                                           & (comments.commenter.isin(test_authors))], username_to_index)\n",
    "        x_train, y_train = get_x(user_indices, index_to_record), get_y(user_to_label, test_authors)\n",
    "        edge_index = get_edge_index(test_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import preprocessing\n",
    "import utils\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch_geometric.data import Data\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv(\"../data/profiles.csv\", usecols=[\"profile_username\", \"profile_followed_by\", \"profile_follow\", \n",
    "                                                        \"medias_nb\", \"comments_nb\", \"comments_commenters_nb\", \n",
    "                                                        \"comments_self_nb\", \"category_1\"])\n",
    "comments = pd.read_csv(\"../data/comments.csv\", usecols=[\"media_short_code\", \"media_author\", \"commenter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = preprocessing.categorical_to_numerical(profiles, col=\"category_1\")\n",
    "comments = comments.drop_duplicates()\n",
    "comments = preprocessing.filter_by_relevance(comments, profiles, minimum_freq=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = profiles.profile_username.unique().tolist()\n",
    "followers = comments.commenter.unique().tolist()\n",
    "all_users = set(known_users + followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = profiles.profile_username.values\n",
    "data = profiles[[\"profile_followed_by\", \"profile_follow\", \"medias_nb\", \n",
    "                \"comments_nb\", \"comments_commenters_nb\", \"comments_self_nb\"]].values\n",
    "name_to_record = {name: record for name, record in zip(names, data)}\n",
    "\n",
    "input_dim, output_dim = data.shape[1], len(profiles.category_1.unique()) + 1\n",
    "user_to_label = {user: category for user, category in profiles[[\"profile_username\", \"category_1\"]].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_histories(models_histories, new_histories):\n",
    "    for model, history in new_histories.items():\n",
    "        if not models_histories[model]:\n",
    "            models_histories[model] = np.array(new_histories[model])\n",
    "        else:\n",
    "            models_histories[model] += np.array(new_histories[model])\n",
    "    \n",
    "    return models_histories\n",
    "    \n",
    "\n",
    "def calculate_statistics(models_metrics):\n",
    "    return {model: {metric: (np.mean(values), np.std(values)) for metric, values in metrics.items()} \n",
    "                for model, metrics in models_metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fez of preprocessamento\n",
      "Pegou autores\n",
      "Pegou indices\n",
      "Pegou interações\n",
      "Pegou x e y\n",
      "Pegou os indices de arestas\n",
      "Criou Data\n",
      "Criou modelos\n",
      "GCN running loss is: 669.4345092773438\n",
      "Treinou o Modelo GCNModel(\n",
      "  (conv1): GCNConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GAT running loss is: 971253.8125\n",
      "Treinou o Modelo GATModel(\n",
      "  (conv1): GATConv(6, 5, heads=8)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GraphSAGE running loss is: 175443.90625\n",
      "Treinou o Modelo GraphSAGE(\n",
      "  (conv1): SAGEConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "Pegou autores\n",
      "Pegou indices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/guilherme/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegou interações\n",
      "Pegou x e y\n",
      "Pegou os indices de arestas\n",
      "Criou Data\n",
      "Criou modelos\n",
      "GCN running loss is: 204542.75\n",
      "Treinou o Modelo GCNModel(\n",
      "  (conv1): GCNConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GAT running loss is: 4479977.5\n",
      "Treinou o Modelo GATModel(\n",
      "  (conv1): GATConv(6, 5, heads=8)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GraphSAGE running loss is: 1251.4002685546875\n",
      "Treinou o Modelo GraphSAGE(\n",
      "  (conv1): SAGEConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "Pegou autores\n",
      "Pegou indices\n",
      "Pegou interações\n",
      "Pegou x e y\n",
      "Pegou os indices de arestas\n",
      "Criou Data\n",
      "Criou modelos\n",
      "GCN running loss is: 172875.3125\n",
      "Treinou o Modelo GCNModel(\n",
      "  (conv1): GCNConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GAT running loss is: 3469048.0\n",
      "Treinou o Modelo GATModel(\n",
      "  (conv1): GATConv(6, 5, heads=8)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GraphSAGE running loss is: 496122.09375\n",
      "Treinou o Modelo GraphSAGE(\n",
      "  (conv1): SAGEConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "Pegou autores\n",
      "Pegou indices\n",
      "Pegou interações\n",
      "Pegou x e y\n",
      "Pegou os indices de arestas\n",
      "Criou Data\n",
      "Criou modelos\n",
      "GCN running loss is: 292686.40625\n",
      "Treinou o Modelo GCNModel(\n",
      "  (conv1): GCNConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GAT running loss is: 4279342.0\n",
      "Treinou o Modelo GATModel(\n",
      "  (conv1): GATConv(6, 5, heads=8)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GraphSAGE running loss is: 270112.375\n",
      "Treinou o Modelo GraphSAGE(\n",
      "  (conv1): SAGEConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "Pegou autores\n",
      "Pegou indices\n",
      "Pegou interações\n",
      "Pegou x e y\n",
      "Pegou os indices de arestas\n",
      "Criou Data\n",
      "Criou modelos\n",
      "GCN running loss is: 4527.3984375\n",
      "Treinou o Modelo GCNModel(\n",
      "  (conv1): GCNConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GAT running loss is: 5511783.5\n",
      "Treinou o Modelo GATModel(\n",
      "  (conv1): GATConv(6, 5, heads=8)\n",
      "  (loss): NLLLoss()\n",
      ")\n",
      "GraphSAGE running loss is: 973545.375\n",
      "Treinou o Modelo GraphSAGE(\n",
      "  (conv1): SAGEConv(6, 5)\n",
      "  (loss): NLLLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "skf = StratifiedKFold(n_splits=K)\n",
    "\n",
    "n_hidden_units = 64\n",
    "print(\"Fez of preprocessamento\")\n",
    "models_metrics = defaultdict(dict)\n",
    "models_histories = defaultdict(list)\n",
    "for train_idx, test_idx in skf.split(profiles.profile_username.values, profiles.category_1.values):\n",
    "    train_authors, test_authors = utils.get_authors(profiles, all_users, train_idx, test_idx)\n",
    "\n",
    "    print(\"Pegou autores\")\n",
    "\n",
    "    username_to_index = utils.get_users_indices(train_authors)\n",
    "    print(\"Pegou indices\")\n",
    "    train_interactions = utils.get_interactions(comments[(comments.media_author.isin(train_authors)) \n",
    "                                                    & (comments.commenter.isin(train_authors))], username_to_index)\n",
    "    print(\"Pegou interações\")\n",
    "    x_train, y_train = utils.get_x(train_authors, name_to_record, input_dim=input_dim), utils.get_y(user_to_label, train_authors)\n",
    "    print(\"Pegou x e y\")\n",
    "    assert len(x_train)==len(y_train), \"Train Input and Output tensor do not have the same dimensions\"\n",
    "\n",
    "\n",
    "    edge_index = utils.get_edge_index(train_interactions)\n",
    "    print(\"Pegou os indices de arestas\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data = Data(x=x_train, y=y_train, edge_index=edge_index).to(device)\n",
    "    print(\"Criou Data\")\n",
    "\n",
    "    models = utils.get_models(data.num_nodes, input_dim, output_dim, n_hidden_units, device=device, lr=0.005)\n",
    "    print(\"Criou modelos\")\n",
    "\n",
    "    histories = utils.train(data, models, epochs=1)\n",
    "    models_histories = update_histories(models_histories, histories)\n",
    "\n",
    "    username_to_index = utils.get_users_indices(test_authors)\n",
    "    test_interactions = utils.get_interactions(comments[(comments.media_author.isin(test_authors)) \n",
    "                                                    & (comments.commenter.isin(test_authors))], username_to_index)\n",
    "    x_test, y_test = utils.get_x(test_authors, name_to_record, input_dim=input_dim), utils.get_y(user_to_label, test_authors)\n",
    "    assert len(x_test)==len(y_test), \"Test Input and Output tensor do not have the same dimensions\"\n",
    "\n",
    "    edge_index = utils.get_edge_index(test_interactions)\n",
    "    data = Data(x=x_test, y=y_test, edge_index=edge_index).to(device)\n",
    "    current_metrics = utils.test(data, models)\n",
    "    utils.update_metrics_dict(models_metrics, current_metrics)\n",
    "    \n",
    "models_histories = {model: list(history/K) for model, history in models_histories.items()} # Get mean traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(models_metrics):\n",
    "    return {model: {metric: (np.mean(values), np.std(values)) for metric, values in metrics.items()} \n",
    "                for model, metrics in models_metrics.items()}\n",
    "\n",
    "models_metrics = calculate_statistics(models_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('models_histories.json', 'w') as fp:\n",
    "    json.dump(models_histories, fp)\n",
    "    \n",
    "with open('models_metrics.json', 'w') as fp:\n",
    "    json.dump(models_metrics, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
