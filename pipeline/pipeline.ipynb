{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Set a seed ✓\n",
    "- Read data ✓\n",
    "- Check nulls ✓\n",
    "- How many users? ✓\n",
    "- How many categories? ✓\n",
    "    - How much records does each one have? ✓\n",
    "- How many posts? ✓\n",
    "- How many interactions? ✓\n",
    "- What is the average interactions per post? ✓\n",
    "- Remove \"insignificant\" connections. ✓\n",
    "- How representative was the reduction? ✓\n",
    "- Create a reasonable visualization from the graph (e.g. Gephi)\n",
    "- Create a mapping from all names to indices (e.g. LabelEncoder). How to get all names? ✓\n",
    "- Create a mapping from all labels to an indices. ✓\n",
    "- Create a mapping from all nodes to a label index. ✓\n",
    "- Create a toy model (e.g. the GCN example provided in the documentation). ✓\n",
    "- Check if the data object was created correctly. \n",
    "- Define the embedding dimension.\n",
    "- Create and save a [Node2Vec](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.models.Node2Vec) model. ✓\n",
    "- Create and save a [GCN](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) model. ✓\n",
    "- Create ans save a [GAT](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GATConv) model.\n",
    "- Create ans save a [SAGE](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv) model.\n",
    "- Create ans save a [GIN](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GINConv) model.\n",
    "- Use a t-SNE and plot the classes with different colors.\n",
    "- How consistent are the embeddings? \n",
    "- Do they group well together?\n",
    "- From which models does the greatest embeddings come from?\n",
    "- Which metric will be optimized by the learning models?\n",
    "- Which model should be used to classify the nodes?\n",
    "    - If a neural model:\n",
    "        - Which learning rate? Is it adaptive? \n",
    "        - How many epochs? \n",
    "        - Which architecture?\n",
    "        - Present a training erro vs test error analysis chart.\n",
    "- Which categories reach the greatest performance? \n",
    "    - Why?\n",
    "    - Is there any pausible reason or maybe characteristic from a method/family of methods that helps to perform better in our case? If so, what is?\n",
    "- \n",
    "   \n",
    "Resources:\n",
    "- https://graphreason.github.io/papers/39.pdf (Must Read)\n",
    "- https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\n",
    "- https://pytorch-geometric.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn.models import Node2Vec\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv\n",
    "from torch.optim import Adam\n",
    "from torch.nn import NLLLoss\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv(\"../data/profiles.csv\", usecols=[\"profile_username\", \"category_1\"]).drop_duplicates()\n",
    "profiles.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"../data/comments.csv\", usecols=[\"media_short_code\", \"media_author\", \"commenter\"])\n",
    "comments = comments.drop_duplicates()\n",
    "comments.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = profiles.category_1.value_counts()\n",
    "\n",
    "figure = go.Figure(\n",
    "    data=[go.Pie(labels=results.index.values, values=results.values)],\n",
    "    layout_title_text=\"Percentage of Each Category\"\n",
    ")\n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_index = {category: index for index, category in enumerate(results.index)}\n",
    "profiles.category_1 = profiles.category_1.map(lambda key: category_to_index[key])\n",
    "profiles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = profiles.profile_username.unique().tolist()\n",
    "followers = comments.commenter.unique().tolist()\n",
    "prev_number_of_users = len(set(known_users + followers))\n",
    "\n",
    "print(\"There are originally {} users\".format(prev_number_of_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts = len(comments.media_short_code.unique())\n",
    "all_interactions = len(comments)\n",
    "print(\"There are {} distinct posts and {} interactions. An average of {} interactions per post\"\\\n",
    "          .format(all_posts, all_interactions, np.round(all_interactions/all_posts, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEVANCE_THRESHOLD = 5\n",
    "subgraph = []\n",
    "for commenter, frequency in comments.commenter.value_counts().items():\n",
    "    if frequency > RELEVANCE_THRESHOLD:\n",
    "        subgraph.append(commenter)\n",
    "        \n",
    "comments = comments[comments.commenter.isin(subgraph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = profiles.profile_username.unique().tolist()\n",
    "followers = comments.commenter.unique().tolist()\n",
    "all_users = set(known_users + followers)\n",
    "cur_number_of_users = len(all_users)\n",
    "\n",
    "print(\"The new graph drawn from relevance threshold {} has {} users and {} interactions\"\\\n",
    "          .format(RELEVANCE_THRESHOLD, cur_number_of_users, len(comments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of users was reduced by ~ {}%\"\\\n",
    "          .format(np.round(1-cur_number_of_users/prev_number_of_users, 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username_to_index = {name: index for index, name in enumerate(all_users)}\n",
    "all_users_indices = [username_to_index[user] for user in username_to_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_label = {user: category for user, category in profiles[[\"profile_username\", \"category_1\"]].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [(username_to_index[author], username_to_index[commenter]) \n",
    "                    for author, commenter in comments[['media_author', 'commenter']].drop_duplicates().values]\n",
    "\n",
    "print(\"The final graph has {} interactions\".format(len(interactions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "graph.add_edges_from(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(all_users_indices, dtype=torch.long).view(-1, 1)\n",
    "y = torch.tensor([user_to_label.get(user, 4) for user in all_users], dtype=torch.float)\n",
    "edge_index = torch.tensor(nx.to_pandas_edgelist(graph).values.T, dtype=torch.long)\n",
    "\n",
    "assert len(x)==len(y), \"Input and Output tensor do not have the same dimensions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = Data(x=x, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script False\n",
    "\n",
    "class Node2VecModel(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Node2VecModel, self).__init__()\n",
    "        self.model = Node2Vec(*args, **kwargs)\n",
    "        \n",
    "        self.optimizer = Adam(self.model.parameters(), lr=0.01)\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "        \n",
    "    def fit(self, data, epochs=10):\n",
    "        data_loader = DataLoader(torch.arange(data.num_nodes), batch_size=128, shuffle=True)\n",
    "        self.train() # To set the modules in training state\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for subset in data_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self.model.loss(data.edge_index, subset)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "            \n",
    "            print(\"The running loss is: {}\".format(running_loss / len(loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script False\n",
    "\n",
    "n2v = Node2VecModel(data.num_nodes, embedding_dim=128, walk_length=20, context_size=10, walks_per_node=10)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n2v, data = n2v.to(device), data.to(device)\n",
    "\n",
    "n2v.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script False\n",
    "\n",
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_hidden_units, n_classes, **kwargs):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(n_features, n_hidden_units, cached=True)\n",
    "        self.conv2 = GCNConv(n_hidden_units, n_classes, cached=True)\n",
    "        \n",
    "        self.loss = NLLLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs=10):\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.forward(data.x, data.edge_index)\n",
    "            loss = self.loss(outputs[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            print(\"The running loss is: {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script False\n",
    "\n",
    "gcn = GCNModel(dataset.num_features, 16, dataset.num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gcn, data = gcn.to(device), data.to(device)\n",
    "\n",
    "gcn.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_hidden_units, n_classes):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(n_features, n_hidden_units, heads=8, dropout=0.6)\n",
    "        self.conv2 = GATConv(n_hidden_units**2, n_classes, heads=1, concat=True, dropout=0.6)\n",
    "        \n",
    "        self.loss = NLLLoss()\n",
    "        self.optimizer = Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs=10):\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            outputs = self.forward(data.x, data.edge_index)\n",
    "            loss = self.loss(outputs[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            print(\"The running loss is: {}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script False\n",
    "\n",
    "gat = GATModel(dataset.num_features, 8, dataset.num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gat, data = gat.to(device), data.to(device)\n",
    "\n",
    "gat.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
