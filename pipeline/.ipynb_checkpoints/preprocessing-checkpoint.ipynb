{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Read data ✓\n",
    "- Check nulls ✓\n",
    "- How many users? ✓\n",
    "- How many categories? ✓\n",
    "    - How much records does each one have? ✓\n",
    "- How many posts? ✓\n",
    "- How many interactions? ✓\n",
    "- What is the average interactions per post? ✓\n",
    "- Remove \"insignificant\" connections. ✓\n",
    "- How representative was the reduction? ✓\n",
    "- Create a reasonable visualization from the graph (e.g. Gephi)\n",
    "- Create a mapping from all names to indices (e.g. LabelEncoder). How to get all names? ✓\n",
    "- Create a mapping from all labels to an indices. ✓\n",
    "- Create a mapping from all nodes to a label index. ✓\n",
    "- Create a toy model (e.g. the GCN example provided in the documentation).\n",
    "- Check if the data object was created correctly.\n",
    "- Define the embedding dimension.\n",
    "- Create and save a Node2Vec model.\n",
    "- Create and save a GCN model.\n",
    "- Create ans save a GAT model.\n",
    "- Create ans save a GraphSAGE model.\n",
    "- Create ans save a GIN model.\n",
    "- Use a t-SNE and plot the classes with different colors.\n",
    "- How consistent are the embeddings? \n",
    "- Do they group well together?\n",
    "- From which models does the greatest embeddings come from?\n",
    "- Which metric will be optimized by the learning models?\n",
    "- Which model should be used to classify the nodes?\n",
    "    - If a neural model:\n",
    "        - Which learning rate? Is it adaptive? \n",
    "        - How many epochs? \n",
    "        - Which architecture?\n",
    "        - Present a training erro vs test error analysis chart.\n",
    "- Which categories reach the greatest performance? \n",
    "    - Why?\n",
    "    - Is there any pausible reason or maybe characteristic from a method/family of methods that helps to perform better in our case? If so, what is?\n",
    "- \n",
    "   \n",
    "Resources:\n",
    "- https://graphreason.github.io/papers/39.pdf (Must Read)\n",
    "- https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8\n",
    "- https://pytorch-geometric.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import missingno as msno\n",
    "import ast\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.data import Data\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.read_csv(\"../data/profiles.csv\", usecols=[\"profile_username\", \"category_1\"]).drop_duplicates()\n",
    "profiles.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"../data/comments.csv\", usecols=[\"media_short_code\", \"media_author\", \"commenter\"])\n",
    "comments = comments.drop_duplicates()\n",
    "comments.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = profiles.category_1.value_counts()\n",
    "\n",
    "figure = go.Figure(\n",
    "    data=[go.Pie(labels=results.index.values, values=results.values)],\n",
    "    layout_title_text=\"Percentage of Each Category\"\n",
    ")\n",
    "\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_index = {category: index for index, category in enumerate(results.index)}\n",
    "profiles.category_1 = profiles.category_1.map(lambda key: category_to_index[key])\n",
    "profiles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = profiles.profile_username.unique().tolist()\n",
    "followers = comments.commenter.unique().tolist()\n",
    "prev_number_of_users = len(set(known_users + followers))\n",
    "\n",
    "print(\"There are originally {} users\".format(prev_number_of_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts = len(comments.media_short_code.unique())\n",
    "all_interactions = len(comments)\n",
    "print(\"There are {} distinct posts and {} interactions. An average of {} interactions per post\"\\\n",
    "          .format(all_posts, all_interactions, np.round(all_interactions/all_posts, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEVANCE_THRESHOLD = 5\n",
    "subgraph = []\n",
    "for commenter, frequency in comments.commenter.value_counts().items():\n",
    "    if frequency > RELEVANCE_THRESHOLD:\n",
    "        subgraph.append(commenter)\n",
    "        \n",
    "comments = comments[comments.commenter.isin(subgraph)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = profiles.profile_username.unique().tolist()\n",
    "followers = comments.commenter.unique().tolist()\n",
    "all_users = set(known_users + followers)\n",
    "cur_number_of_users = len(all_users)\n",
    "\n",
    "print(\"The new graph drawn from relevance threshold {} has {} users and {} interactions\"\\\n",
    "          .format(RELEVANCE_THRESHOLD, cur_number_of_users, len(comments)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of users was reduced by ~ {}%\"\\\n",
    "          .format(np.round(1-cur_number_of_users/prev_number_of_users, 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username_to_index = {name: index for index, name in enumerate(all_users)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_label = {user: category for user, category in profiles[[\"profile_username\", \"category_1\"]].values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = [(username_to_index[author], username_to_index[commenter]) \n",
    "                    for author, commenter in comments[['media_author', 'commenter']].drop_duplicates().values]\n",
    "\n",
    "print(\"The final graph has {} interactions\".format(len(interactions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "graph.add_edges_from(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(graph.nodes, dtype=torch.float).view(-1, 1)\n",
    "# x = torch.LongTensor(graph.nodes).view(-1, 1)\n",
    "y = torch.tensor([user_to_label.get(user, 4) for user in all_users], dtype=torch.float)\n",
    "edge_index = torch.tensor(nx.to_pandas_edgelist(graph).values.T, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
    "class SAGEConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SAGEConv, self).__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.update_lin = torch.nn.Linear(in_channels + out_channels, in_channels, bias=False)\n",
    "        self.update_act = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        \n",
    "        \n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        \n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        x_j = self.lin(x_j)\n",
    "        x_j = self.act(x_j)\n",
    "        \n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "\n",
    "        new_embedding = torch.cat([aggr_out, x], dim=1)\n",
    "        \n",
    "        new_embedding = self.update_lin(new_embedding)\n",
    "        new_embedding = self.update_act(new_embedding)\n",
    "        \n",
    "        return new_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGEConv(data.x.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(data.x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
